"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = exports.parse = void 0;

var _core = require("@citation-js/core");

var _tokens = _interopRequireDefault(require("./tokens.json"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const tokenPattern = /\\url|\\href|{\\[a-zA-Z]+}|\$\\[a-zA-Z]+\$|\$[_^]{[0-9()+=\-n]}\$|`{2,3}|'{2,3}|-{2,3}|[!?]!|!\?|{\\~}|\\[#$%&~_^\\{}]|{\\(?:[a-z] |[`"'^~=.])\\?[a-zA-Z]}|[\s\S]/g;
const whitespace = /^\s$/;
const syntax = /^[@{}"=,\\]$/;
const delimiters = {
  '"': '"',
  '{': '}',
  '': ''
};

const getTokenizedBibtex = function getTokenizedBibtex(str) {
  str = str.replace(/(\\[`"'^~=.]){\\?([A-Za-z])}/g, '{$1$2}').replace(/(\\[a-z]) ?{\\?([A-Za-z])}/g, '{$1 $2}');
  return str.match(tokenPattern);
};

const parseBibTeX = function parseBibTeX(str) {
  const entries = [];
  const tokens = getTokenizedBibtex(str);
  const stack = new _core.util.TokenStack(tokens);

  try {
    stack.consumeWhitespace();

    while (stack.tokensLeft()) {
      stack.consumeToken('@', {
        spaced: false
      });
      stack.consumeWhitespace();
      const type = stack.consume([whitespace, syntax], {
        inverse: true
      }).toLowerCase();
      stack.consumeToken('{');
      const label = stack.consume([whitespace, syntax], {
        inverse: true
      });
      stack.consumeToken(',');
      const properties = {};

      while (stack.tokensLeft()) {
        const key = stack.consume([whitespace, '='], {
          inverse: true
        }).toLowerCase();
        stack.consumeToken('=');
        const startDelimiter = stack.consume(/^({|"|)$/g);
        const endDelimiter = delimiters[startDelimiter];

        if (!delimiters.hasOwnProperty(startDelimiter)) {
          throw new SyntaxError(`Unexpected field delimiter at index ${stack.index}. Expected ` + `${Object.keys(delimiters).map(v => `"${v}"`).join(', ')}; got "${startDelimiter}"`);
        }

        const tokenMap = token => {
          if (_tokens.default.hasOwnProperty(token)) {
            return _tokens.default[token];
          } else if (token.match(/^\\[#$%&~_^\\{}]$/)) {
            return token.slice(1);
          } else if (token.length > 1) {
            throw new SyntaxError(`Escape sequence not recognized: ${token}`);
          } else {
            return token;
          }
        };

        let openBrackets = 0;
        const val = stack.consume((token, index) => {
          if (token === '{') {
            openBrackets++;
          }

          if (stack.tokensLeft() < endDelimiter.length) {
            throw new SyntaxError(`Unmatched delimiter at index ${stack.index}: Expected ${endDelimiter}`);
          } else if (!endDelimiter.length) {
            return ![whitespace, syntax].some(rgx => rgx.test(token));
          } else {
            return token === '}' && openBrackets-- || !stack.matchesSequence(endDelimiter);
          }
        }, {
          tokenMap
        });
        properties[key] = val;
        stack.consumeN(endDelimiter.length);
        stack.consumeWhitespace();

        if (stack.matches('}')) {
          break;
        }

        stack.consumeToken(',', {
          spaced: false
        });
        stack.consumeWhitespace();

        if (stack.matches('}')) {
          break;
        }
      }

      stack.consumeToken('}', {
        spaced: false
      });
      stack.consumeWhitespace();

      if (stack.matches(',')) {
        stack.consumeToken(',');
        stack.consumeWhitespace();
      }

      entries.push({
        type,
        label,
        properties
      });
    }
  } catch (e) {
    logger.error(`Uncaught SyntaxError: ${e.message}. Returning completed entries.`);
    entries.pop();
  }

  return entries;
};

exports.default = exports.parse = parseBibTeX;